# --- Step 1: Tokenizer ---
class Tokenizer
  @input: untyped

  @pos: untyped

  KEYWORDS: ::Array["true" | "false"]

  SYMBOLS: ::Array["+" | "?" | ":" | "(" | ")" | "=>" | ","]

  def initialize: (untyped input) -> void

  def next_token: () -> (nil | "=>" | untyped)

  def read_ident: () -> { type: :ident, value: untyped }

  def tokenize: () -> untyped

  private

  def skip_whitespace: () -> untyped

  def eof?: () -> untyped

  def peek: () -> untyped

  def read_number: () -> { type: :number, value: untyped }

  def read_keyword: () -> ({ type: :keyword, value: untyped } | nil)
end

# --- Step 3: Literal Parser ---
class Parser
  @tokens: untyped

  @pos: untyped

  def initialize: (untyped input) -> void

  def parse: () -> untyped

  private

  # if式: cond ? thn : els
  def parse_if: () -> untyped

  # 加算式: term = call ("+" call)*
  def parse_term: () -> untyped

  # 関数呼び出し: call = factor ("(" args ")")*
  def parse_call: () -> untyped

  # factor: 数値・true/false・括弧
  def parse_factor: () -> untyped

  # (x: number, y: boolean) => body
  def parse_func: () -> { tag: "func", params: untyped, body: untyped }

  # Type型のパース
  def parse_type: () -> untyped

  def func_param_list?: () -> (false | untyped)

  def next_token: () -> (nil | untyped)

  def peek_token: () -> (nil | untyped)

  def expect_token: (untyped val) -> untyped
end
